---
title: 机器学习入门笔记1
date: 2017-09-14 16:05:13
tags: machinelearning
categories: 机器学习
---
原文[http://www.shareditor.com/blogshow?blogId=28](http://www.shareditor.com/blogshow?blogId=28)
<!-- more -->

## 安装octave绘制3D函数图像

<!-- more -->

[http://www.shareditor.com/blogshow?blogId=28](http://www.shareditor.com/blogshow?blogId=28)

```
apt-get install octave
```

## 用scikit-learn求解一元线性回归问题

[原文](http://www.shareditor.com/blogshow?blogId=54)

### scikit-learn的一元线性回归

安装[scikit-learn](http://scikit-learn.org/stable/install.html)

```
pip install -U scikit-learn numpy scipy
```

[LinearRegression文档](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

代码`scikit_learn_linear_model_demo.py`

```python
import numpy as np
from sklearn.linear_model import LinearRegression

x = [[1],[2],[3],[4],[5],[6]]
y = [[1],[2.1],[2.9],[4.2],[5.1],[5.8]]
model = LinearRegression()
model.fit(x, y)
predicted = model.predict(13)
print predicted
```

输出

```
[[ 12.82666667]]
```

### 画一元线性图像

安装

```
apt-get install -y python-dev python-tk
pip install matplotlib
```

代码`plot_linear.py`

```python
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
font = FontProperties()

plt.figure()
plt.title('linear sample')
plt.xlabel('x')
plt.ylabel('y')
plt.axis([0, 10, 0, 10])
plt.grid(True)
x = [[1],[2],[3],[4],[5],[6]]
y = [[1],[2.1],[2.9],[4.2],[5.1],[5.8]]
plt.plot(x, y, 'k.')
plt.show()
```

> plot()函数的第三个参数非常简单：k表示卡其色khaki，g表示绿色green，r表示红色red，'.'表示点，'-'表示线

预测加画图代码

```python
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

x = [[1],[2],[3],[4],[5],[6]]
y = [[1],[2.1],[2.9],[4.2],[5.1],[5.8]]
model = LinearRegression()
model.fit(x, y)
x2 = [[0], [2.5], [5.3], [9.1]]
y2 = model.predict(x2)

plt.figure()
plt.title('linear sample')
plt.xlabel('x')
plt.ylabel('y')
plt.axis([0, 10, 0, 10])
plt.grid(True)
plt.plot(x, y, 'k.')
plt.plot(x2, y2, 'g-')
plt.show()
```

### 方差

```python
import numpy as np
np.var([1,2,3,4,5,6], ddof=1)
```

> 结果为3.5，ddof是无偏估计校正技术

### 协方差

```python
import numpy as np
np.cov([1,2,3,4,5,6], [1,2.1,2.9,4.2,5.1,5.8])[0][1]
```

### 参数查看

b = 方差/协方差

输入`print model.coef_`

### 模型评估

```python
model.score(x2, y2)
```

## 用scikit-learn求解多元线性回归问题

[原文]()

### 多元线性回归模型

y = x0 + a1 * x1 + a2 * x2 + ...

若方程为 y = 1 + 2 * x1 + 3 * x2

输入 X = [[1,1,1],[1,1,2],[1,2,1]]

计算得到 y = [[6],[9],[8]]

代码`scikit_learn_multvariable_linear_model_demo.py`

```python
from numpy.linalg import inv
from numpy import dot, transpose

X = [[1,1,1],[1,1,2],[1,2,1]]
y = [[6],[9],[8]]

print dot(inv(dot(transpose(X),X)), dot(transpose(X),y))
```

> transpose是求转置，dot是求矩阵乘积，inv是求矩阵的逆

等同于以下代码

```python
from numpy.linalg import lstsq
print lstsq(X, y)[0]
```

> lstsq就是least square最小二乘

结果

```
[[ 1.]
 [ 2.]
 [ 3.]]
```

### 用scikit-learn求解多元线性回归

```python
from sklearn.linear_model import LinearRegression

X = [[1,1,1],[1,1,2],[1,2,1]]
y = [[6],[9],[8]]

model = LinearRegression()
model.fit(X, y)
x2 = [[1,3,5]]
y2 = model.predict(x2)
print y2
```

输出

```
[[ 22.]]
```

## 用matplotlib绘制精美的图表

[原文](http://www.shareditor.com/blogshow?blogId=55)

安装见上文

### 绘制一元函数图像y=ax+b

代码`single_variable.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([0, 5, 0, 10]) # x轴范围0-5，y轴范围0-10
plt.grid(True) # 是否绘制网格线
xx = np.linspace(0, 5, 10) # 在0-5之间生成10个点的向量
plt.plot(xx, 2*xx, 'g-') # 绘制y=2x图像，颜色green，形式为线条
plt.show() # 展示图像
```

### 绘制正弦曲线y=sin(x)

代码`sinx.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([-12, 12, -1, 1]) # x轴范围-12到12，y轴范围-1到1
plt.grid(True) # 是否绘制网格线
xx = np.linspace(-12, 12, 1000) # 在-12到12之间生成1000个点的向量
plt.plot(xx, np.sin(xx), 'g-', label="$sin(x)$") # 绘制y=sin(x)图像，颜色green，形式为线条
plt.plot(xx, np.cos(xx), 'r--', label="$cos(x)$") # 绘制y=cos(x)图像，颜色red，形式为虚线
plt.legend() # 绘制图例
plt.show() # 展示图像
```

> [legend位置](https://matplotlib.org/api/legend_api.html)

### 绘制多轴图

代码`multi_axis.py`

```
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np

def draw(plt):
    plt.axis([-12, 12, -1, 1]) # x轴范围-12到12，y轴范围-1到1
    plt.grid(True) # 是否绘制网格线
    xx = np.linspace(-12, 12, 1000) # 在-12到12之间生成1000个点的向量
    plt.plot(xx, np.sin(xx), 'g-', label="$sin(x)$") # 绘制y=sin(x)图像，颜色green，形式为线条
    plt.plot(xx, np.cos(xx), 'r--', label="$cos(x)$") # 绘制y=cos(x)图像，颜色red，形式为虚线
    plt.legend() # 绘制图例

plt.figure() # 实例化作图变量
plt1 = plt.subplot(2,2,1) # 两行两列中的第1张图
draw(plt1)
plt2 = plt.subplot(2,2,2) # 两行两列中的第2张图
draw(plt2)
plt3 = plt.subplot(2,2,3) # 两行两列中的第3张图
draw(plt3)
plt4 = plt.subplot(2,2,4) # 两行两列中的第4张图
draw(plt4)

plt.show() # 展示图像
```

### 绘制3D图像

代码`plot_3d.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(1,1,1,projection='3d')
theta = np.linspace(-4 * np.pi, 4 * np.pi, 500) # theta旋转角从-4pi到4pi，相当于两圈
z = np.linspace(0, 2, 500) # z轴从下到上,从-2到2之间画100个点
r = z # 半径设置为z大小
x = r * np.sin(theta) # x和y画圆
y = r * np.cos(theta) # x和y画圆
ax.plot(x, y, z, label='curve')
ax.legend()

plt.show()
```

### 3D散点图

代码`plot_3d_scatter.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(1,1,1,projection='3d')
xx = np.linspace(0, 5, 10) # 在0-5之间生成10个点的向量
yy = np.linspace(0, 5, 10) # 在0-5之间生成10个点的向量
zz1 = xx
zz2 = 2*xx
zz3 = 3*xx
ax.scatter(xx, yy, zz1, c='red', marker='o') # o型符号
ax.scatter(xx, yy, zz2, c='green', marker='^') # 三角型符号
ax.scatter(xx, yy, zz3, c='black', marker='*') # 星型符号
ax.legend()

plt.show()
```

### 绘制3D表面

代码`plot_3d_surface.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure()
ax = fig.gca(projection='3d')

X = np.arange(-5, 5, 0.25)
Y = np.arange(-5, 5, 0.25)
X, Y = np.meshgrid(X, Y)

Z = X**2+Y**2

ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm, linewidth=0, antialiased=False)

plt.show()
```

## 用scikit-learn求解多项式回归问题

[原文](http://www.shareditor.com/blogshow?blogId=56)

### 住房价格样本

样本 | 面积(平方米) | 价格(万元)
--- | --- | ---
1 | 50 | 150
2 | 100 | 200
3 | 150 | 250
4 | 200 | 280
5 | 250 | 310
6 | 300 | 330

### 做图像

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([30, 400, 100, 400])
plt.grid(True) # 是否绘制网格线

xx = [[50],[100],[150],[200],[250],[300]]
yy = [[150],[200],[250],[280],[310],[330]]
plt.plot(xx, yy, 'k.')
plt.show() # 展示图像
```

### 线性回归

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([30, 400, 100, 400])
plt.grid(True) # 是否绘制网格线

xx = [[50],[100],[150],[200],[250],[300]]
yy = [[150],[200],[250],[280],[310],[330]]
plt.plot(xx, yy, 'k.')

model = LinearRegression()
model.fit(xx, yy)
print model.coef_
x2 = [[30], [400]]
y2 = model.predict(x2)
plt.plot(x2, y2, 'g-')

plt.show() # 展示图像
```

### 采用多项式回归

二次多项式

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([30, 400, 100, 400])
plt.grid(True) # 是否绘制网格线

X = [[50],[100],[150],[200],[250],[300]]
y = [[150],[200],[250],[280],[310],[330]]
X_test = [[250],[300]] # 用来做最终效果测试
y_test = [[310],[330]] # 用来做最终效果测试
plt.plot(X, y, 'k.')

model = LinearRegression()
model.fit(X, y)
X2 = [[30], [400]]
y2 = model.predict(X2)
plt.plot(X2, y2, 'g-')

xx = np.linspace(30, 400, 100) # 设计x轴一系列点作为画图的x点集
quadratic_featurizer = PolynomialFeatures(degree=2) # 实例化一个二次多项式特征实例
X_train_quadratic = quadratic_featurizer.fit_transform(X) # 用二次多项式对样本X值做变换
xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1)) # 把训练好X值的多项式特征实例应用到一系列点上,形成矩阵
regressor_quadratic = LinearRegression() # 创建一个线性回归实例
regressor_quadratic.fit(X_train_quadratic, y) # 以多项式变换后的x值为输入，代入线性回归模型做训练
print regressor_quadratic.coef_
plt.plot(xx, regressor_quadratic.predict(xx_quadratic), 'r-') # 用训练好的模型作图

print '一元线性回归 r-squared', model.score(X_test, y_test)
X_test_quadratic = quadratic_featurizer.transform(X_test)
print '二次回归     r-squared', regressor_quadratic.score(X_test_quadratic, y_test)

plt.show() # 展示图像
```

三次多项式

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.axis([30, 400, 100, 400])
plt.grid(True) # 是否绘制网格线

X = [[50],[100],[150],[200],[250],[300]]
y = [[150],[200],[250],[280],[310],[330]]
X_test = [[250],[300]] # 用来做最终效果测试
y_test = [[310],[330]] # 用来做最终效果测试
plt.plot(X, y, 'k.')

model = LinearRegression()
model.fit(X, y)
X2 = [[30], [400]]
y2 = model.predict(X2)
plt.plot(X2, y2, 'g-')

xx = np.linspace(30, 400, 100) # 设计x轴一系列点作为画图的x点集
quadratic_featurizer = PolynomialFeatures(degree=2) # 实例化一个二次多项式特征实例
X_train_quadratic = quadratic_featurizer.fit_transform(X) # 用二次多项式对样本X值做变换
xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1)) # 把训练好X值的多项式特征实例应用到一系列点上,形成矩阵
regressor_quadratic = LinearRegression() # 创建一个线性回归实例
regressor_quadratic.fit(X_train_quadratic, y) # 以多项式变换后的x值为输入，代入线性回归模型做训练
print regressor_quadratic.coef_
plt.plot(xx, regressor_quadratic.predict(xx_quadratic), 'r-') # 用训练好的模型作图

cubic_featurizer = PolynomialFeatures(degree=3)
X_train_cubic = cubic_featurizer.fit_transform(X)
regressor_cubic = LinearRegression()
regressor_cubic.fit(X_train_cubic, y)
xx_cubic = cubic_featurizer.transform(xx.reshape(xx.shape[0], 1))
plt.plot(xx, regressor_cubic.predict(xx_cubic))

print '一元线性回归 r-squared', model.score(X_test, y_test)
X_test_quadratic = quadratic_featurizer.transform(X_test)
print '二次回归     r-squared', regressor_quadratic.score(X_test_quadratic, y_test)
X_test_cubic = cubic_featurizer.transform(X_test)
print '三次回归     r-squared', regressor_cubic.score(X_test_cubic, y_test)

plt.show() # 展示图像
```

## 用随机梯度下降法(SGD)做线性拟合

scikit-learn的线性回归模型都是通过最小化成本函数来计算参数的，通过矩阵乘法和求逆运算来计算参数。当变量很多的时候计算量会非常大，因此我们改用梯度下降法，批量梯度下降法每次迭代都用所有样本，快速收敛但性能不高，随机梯度下降法每次用一个样本调整参数，逐渐逼近，效率高，本节我们来利用随机梯度下降法做拟合。

### 梯度下降法

梯度下降就好比从一个凹凸不平的山顶快速下到山脚下，每一步都会根据当前的坡度来找一个能最快下来的方向。随机梯度下降英文是Stochastic gradient descend(SGD)，在scikit-learn中叫做SGDRegressor。

### 样本实验

依然用上一节的房价样本

```python
X = [[50],[100],[150],[200],[250],[300]]
y = [[150],[200],[250],[280],[310],[330]]
```

代码`sgd_regressor.py`

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler

plt.figure() # 实例化作图变量
plt.title('single variable') # 图像标题
plt.xlabel('x') # x轴文本
plt.ylabel('y') # y轴文本
plt.grid(True) # 是否绘制网格线

X_scaler = StandardScaler()
y_scaler = StandardScaler()
X = [[50],[100],[150],[200],[250],[300]]
y = [[150],[200],[250],[280],[310],[330]]
X = X_scaler.fit_transform(X)
y = y_scaler.fit_transform(y)
X_test = [[40],[400]] # 用来做最终效果测试
X_test = X_scaler.transform(X_test)

plt.plot(X, y, 'k.')

model = SGDRegressor()
model.fit(X, y.ravel())
y_result = model.predict(X_test)
plt.plot(X_test, y_result, 'g-')

plt.show() # 展示图像
```

效果不好，扩大样本

```python
X = [[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300],[50],[100],[150],[200],[250],[300]]
y = [[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[250],[280],[310],[330],[150],[200],[200],[200],[200],[200]]
```

## 用scikit-learn做特征提取

[原文](http://www.shareditor.com/blogshow?blogId=58)

### 分类变量的特征提取

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn.feature_extraction import DictVectorizer
onehot_encoder = DictVectorizer()
instances = [{'city': '北京'},{'city': '天津'}, {'city': '上海'}]
print(onehot_encoder.fit_transform(instances).toarray())
```

输出

```
[[ 0.  1.  0.]
 [ 0.  0.  1.]
 [ 1.  0.  0.]]
```

### 文字特征提取

文字特征无非这几种：有这个词还是没有、这个词的TF-IDF。

第一种为词库表示法

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn.feature_extraction.text import CountVectorizer
corpus = [
        'UNC played Duke in basketball',
        'Duke lost the basketball game' ]
vectorizer = CountVectorizer()
print vectorizer.fit_transform(corpus).todense()
print vectorizer.vocabulary_
```

输出

```
[[1 1 0 1 0 1 0 1]
 [1 1 1 0 1 0 1 0]]
{u'duke': 1, u'basketball': 0, u'lost': 4, u'played': 5, u'game': 2, u'unc': 7, u'in': 3, u'the': 6}
```

> 数值为1表示词表中的这个词出现，为0表示未出现
> 词表中的数值表示单词的坐标位置

第二种情况TF-IDF表示词的重要性，代码

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn.feature_extraction.text import TfidfVectorizer
corpus = [
        'The dog ate a sandwich and I ate a sandwich',
        'The wizard transfigured a sandwich' ]
vectorizer = TfidfVectorizer(stop_words='english')
print(vectorizer.fit_transform(corpus).todense())
print(vectorizer.vocabulary_)
```

输出

```
[[ 0.75458397  0.37729199  0.53689271  0.          0.        ]
 [ 0.          0.          0.44943642  0.6316672   0.6316672 ]]
{u'sandwich': 2, u'wizard': 4, u'dog': 1, u'transfigured': 3, u'ate': 0}
```

> 值最高的是第一个句子中的ate，因为它在这一个句子里出现了两次
> 值最低的自然是本句子未出现的单词

### 数据标准化

数据标准化就是把数据转成均值为0，是单位方差的。比如对如下矩阵做标准化：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn import preprocessing
import numpy as np
X = np.array([
    [0., 0., 5., 13., 9., 1.],
    [0., 0., 13., 15., 10., 15.],
    [0., 3., 15., 2., 0., 11.]
    ])
print(preprocessing.scale(X))
```

输出

```
[[ 0.         -0.70710678 -1.38873015  0.52489066  0.59299945 -1.35873244]
 [ 0.         -0.70710678  0.46291005  0.87481777  0.81537425  1.01904933]
 [ 0.          1.41421356  0.9258201  -1.39970842 -1.4083737   0.33968311]]
```

## 二元分类效果的评估方法

[原文](http://www.shareditor.com/blogshow?blogId=59)

效果评估是模型选择和算法设计的重要步骤，知道评估优劣才能选择最佳的模型和算法，本节介绍一些有关评估方法的定义，凡是在统计或大数据领域都用得到。

- 真阳性 true positives, TP
- 真阴性 true negatives, TN
- 假阳性 false positives, FP
- 假阴性 false negatives, FN

- 准确率 分类器预测正确性的比例，可以通过LogisticRegression.score() 来计算准确率
- 精确率 分类器预测出的脏话中真的是脏话的比例 P=TP/(TP+FP)
- 召回率 也叫灵敏度。所有真的脏话被分类器正确找出来的比例。 R=TP/(TP+FN)

- 综合评价指标 F-measure，精确率和召回率的调和均值。精确率和召回率都不能从差的分类器中区分出好的分类器，综合评价指标平衡了精确率和召回率。1/F+1/F=1/P+1/R 即 F=2*PR/(P+R)
- 误警率 假阳性率，所有阴性样本中分类器识别为阳性的样本所占比例 F=FP/(TN+FP)
- ROC(Receiver Operating Characteristic) ROC曲线画的是分类器的召回率与误警率(fall-out)的曲线
- AUC(Area Under Curve) ROC曲线下方的面积,它把ROC曲线变成一个值,表示分类器随机预测的效果 scikit-learn画ROC曲线和AUC值的方法如下：

## 用scikit-learn的网格搜索快速找到最优模型参数

[原文](http://www.shareditor.com/blogshow?blogId=60)

任何一种机器学习模型都附带很多参数，不同场景对应不同的最佳参数，手工尝试各种参数无疑浪费很多时间，scikit-learn帮我们实现了自动化，那就是网格搜索。

### 网格搜索

网格指的是不同参数不同取值交叉后形成的一个多维网格空间。比如参数a可以取1、2，参数b可以取3、4，参数c可以取5、6，那么形成的多维网格空间就是：一共2*2*2=8种情况。

网格搜索就是遍历这8种情况进行模型训练和验证，最终选择出效果最优的参数组合

### 用法举例

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model.logistic import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

# 构造样本，这块得多构造点，不然会报class不足的错误，因为gridsearch会拆分成小组
X = []
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")
X.append("fuck me")
X.append("hello boy")
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")
X.append("fuck me")
X.append("hello boy")
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")
X.append("fuck me")
X.append("hello boy")
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")
X.append("fuck me")
X.append("hello boy")
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")
X.append("fuck me")
X.append("hello boy")

y = [1,0,1,0,1,1,0,1,0,1,1,0,1,0,1,1,0,1,0,1,1,0,1,0,1]

# 这是执行的序列，gridsearch是构造多进程顺序执行序列并比较结果
# 这里的vect和clf名字自己随便起，但是要和parameters中的前缀对应
pipeline = Pipeline([
    ('vect', TfidfVectorizer(stop_words='english')),
    ('clf', LogisticRegression())
    ])

# 这里面的max_features必须是TfidfVectorizer的参数, 里面的取值就是子进程分别执行所用
parameters = {
        'vect__max_features': (3, 5),
        }

# accuracy表示按精确度判断最优值
grid_search = GridSearchCV(pipeline, parameters, n_jobs = -1, verbose = 1, scoring = 'accuracy', cv = 3)
grid_search.fit(X, y)

print '最佳效果: %0.3f' % grid_search.best_score_
print '最优参数组合: '
best_parameters = grid_search.best_estimator_.get_params()
for param_name in sorted(parameters.keys()):
    print('\t%s: %r' % (param_name, best_parameters[param_name]))
```

输出

```
Fitting 3 folds for each of 2 candidates, totalling 6 fits
[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished
最佳效果: 0.800
最优参数组合: 
    vect__max_features: 3
```

## 用scikit-learn做聚类分析

[原文](http://www.shareditor.com/blogshow?blogId=61)

线性回归和逻辑回归都是监督学习方法，聚类分析是非监督学习的一种，可以从一批数据集中探索信息，比如在社交网络数据中可以识别社区，在一堆菜谱中识别出菜系。本节介绍K-means聚类算法。

### K-means

k是一个超参数，表示要聚类成多少类。K-means计算方法是重复移动类的重心，以实现成本函数最小化。

![image](http://upload-images.jianshu.io/upload_images/5952841-ca3ad22a3713304c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 试验

构造一些样本用户试验，如下：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np

# 生成2*10的矩阵，且值均匀分布的随机数
cluster1 = np.random.uniform(0.5, 1.5, (2, 10))
cluster2 = np.random.uniform(3.5, 4.5, (2, 10))

# 顺序连接两个矩阵，形成一个新矩阵,所以生成了一个2*20的矩阵，T做转置后变成20*2的矩阵,刚好是一堆(x,y)的坐标点
X = np.hstack((cluster1, cluster2)).T

plt.figure()
plt.axis([0, 5, 0, 5])
plt.grid(True)
plt.plot(X[:,0],X[:,1],'k.')
plt.show()
```

通过k-means做聚类，输出重心点，代码：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans

# 生成2*10的矩阵，且值均匀分布的随机数
cluster1 = np.random.uniform(0.5, 1.5, (2, 10))
cluster2 = np.random.uniform(3.5, 4.5, (2, 10))

# 顺序连接两个矩阵，形成一个新矩阵,所以生成了一个2*20的矩阵，T做转置后变成20*2的矩阵,刚好是一堆(x,y)的坐标点
X = np.hstack((cluster1, cluster2)).T

plt.figure()
plt.axis([0, 5, 0, 5])
plt.grid(True)
plt.plot(X[:,0],X[:,1],'k.')

kmeans = KMeans(n_clusters=2)
kmeans.fit(X)
plt.plot(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], 'ro')

plt.show()
```

### 肘部法则

现实情况是多个点并不像上面这么聚类清晰，你说不清它应该聚类成2、3、4个点，因此我们需要通过分别计算k=(2,3,4)的聚类结果，并比较他们的成本函数值，随着k的增大，成本函数值会不断降低，只有快速降低的那个k值才是最合适的k值，如下：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist

# 生成2*10的矩阵，且值均匀分布的随机数
cluster1 = np.random.uniform(0.5, 1.5, (2, 10))
cluster2 = np.random.uniform(1.5, 2.5, (2, 10))
cluster3 = np.random.uniform(1.5, 3.5, (2, 10))
cluster4 = np.random.uniform(3.5, 4.5, (2, 10))

# 顺序连接两个矩阵，形成一个新矩阵,所以生成了一个2*20的矩阵，T做转置后变成20*2的矩阵,刚好是一堆(x,y)的坐标点
X1 = np.hstack((cluster1, cluster2))
X2 = np.hstack((cluster3, cluster4))
X = np.hstack((X1, X2)).T

K = range(1, 10)
meandistortions = []
for k in K:
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X)
    # 求kmeans的成本函数值
    meandistortions.append(sum(np.min(cdist(X, kmeans.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])

plt.figure()
plt.grid(True)
plt1 = plt.subplot(2,1,1)
# 画样本点
plt1.plot(X[:,0],X[:,1],'k.');
plt2 = plt.subplot(2,1,2)
# 画成本函数值曲线
plt2.plot(K, meandistortions, 'bx-')
plt.show()
```

从曲线上可以看到，随着k的增加，成本函数值在降低，但降低的变化幅度不断在减小，因此急速降低才是最合适的，这里面也许3是比较合适的，你也许会有不同看法

通过这种方法来判断最佳K值的方法叫做肘部法则，你看图像像不像一个人的胳膊肘？

## 神经网络模型的原理

[原文](http://www.shareditor.com/blogshow?blogId=91)

深度学习本质上就是机器学习的一个topic，是深度人工神经网络的另一种叫法，因此理解深度学习首先要理解人工神经网络。

### 人工神经网络

人工神经网络又叫神经网络，是借鉴了生物神经网络的工作原理形成的一种数学模型。下面是一张生物神经元的图示：

![image](http://upload-images.jianshu.io/upload_images/5952841-986482e24ba3ba94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

生物神经网络就是由大量神经元构成的网络结构，如下图.

![image](http://upload-images.jianshu.io/upload_images/5952841-c2b88e993c447a41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

生物的神经网络是通过神经元、细胞、触电等结构组成的一个大型网络结构，用来帮助生物进行思考和行动等。那么人们就想到了电脑是不是也可以像人脑一样具有这种结构，这样是不是就可以思考了？

类似于神经元的结构，人工神经网络也是基于这样的神经元组成：

![image](http://upload-images.jianshu.io/upload_images/5952841-73334612e0c5fca1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里面的x1、x2、x3是输入值，中间的圆就像是神经元，经过它的计算得出hw,b(x)的结果作为神经元的输出值。

由这样的神经元组成的网络就是人工神经网络：

![image](http://upload-images.jianshu.io/upload_images/5952841-449dd965ca874e5a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中橙色的圆都是用来计算hw,b(x)的，纵向我们叫做层（Layer），每一层都以前一层为输入，输出的结果传递给下一层。

### 这样的结构有什么特别的吗？

如果我们把神经网络看做一个黑盒，那么x1、x2、x3是这个黑盒的输入X，最右面的hw,b(x)是这个黑盒的输出Y，按照之前几篇机器学习的文章可以知道：这可以通过一个数学模型来拟合，通过大量训练数据来训练这个模型，之后就可以预估新的样本X应该得出什么样的Y。

但是使用普通的机器学习算法训练出的模型一般都比较肤浅，就像是生物的进化过程，如果告诉你很久以前地球上只有三叶虫，现在地球上有各种各样的生物，你能用简单的模型来表示由三叶虫到人类的进化过程吗？不能。但是如果模拟出中间已知的多层隐藏的阶段（低等原始生物、无脊椎动物、脊椎动物、鱼类、两栖类、爬行动物、哺乳动物、人类时代）就可以通过海量的训练数据模拟出。

也可以类比成md5算法的实现，给你无数个输入字符串和它的md5值，你能用肤浅的算法推出md5的算法吗？不能。因为md5的计算是一阶段一阶段的，后一阶段的输入依赖前一阶段的结果，无法逆推。但是如果已知中间几个阶段，只是不知道这几个阶段的参数，那么可以通过海量数据训练出来。

以上说明了神经网络结构的特别之处：通过较深的多个层次来模拟真实情况，从而构造出最能表达真实世界的模型，它的成本就是海量的训练数据和巨大的计算量。

### 神经网络模型的数学原理

每一个神经元的数学模型是：

![image](http://upload-images.jianshu.io/upload_images/5952841-bfa0007583ffb971.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中的矩阵向量乘法

![image](http://upload-images.jianshu.io/upload_images/5952841-f44a3990d2c86c1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

表示的就是输入多个数据的加权求和，这里的b（也就是上面图中的+1）是截距值，用来约束参数值，就像是一个向量(1,2,3)可以写成(2,4,6)也可以写成(10,20,30)，那么我们必须取定一个值，有了截距值就可以限定了

其中f叫做激活函数，激活函数的设计有如下要求：1）保证后期计算量尽量小；2）固定取值范围；3）满足某个合理的分布。常用的激活函数是sigmond函数和双曲正切函数(tanh)：

sigmond函数：

![image](http://upload-images.jianshu.io/upload_images/5952841-5e47c4ca75a3fa26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![image](http://upload-images.jianshu.io/upload_images/5952841-59773d1f93f3c91f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

双曲正切函数(tanh)：

![image](http://upload-images.jianshu.io/upload_images/5952841-0f4d6c7d380ca89d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![image](http://upload-images.jianshu.io/upload_images/5952841-c6f2299b1fd57581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这两个函数显然满足2）固定取值范围；3）满足某个合理的分布，那么对于1）保证后期计算量尽量小这个要求来说，他们的好处在于：

sigmond函数的导数是：

![image](http://upload-images.jianshu.io/upload_images/5952841-f9814a323aae8716.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

tanh函数的导数是：

![image](http://upload-images.jianshu.io/upload_images/5952841-356703a80130b120.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这会减少非常多的计算量，后面就知道了。

当计算多层的神经网络时，对于如下三层神经网络来说

![image](http://upload-images.jianshu.io/upload_images/5952841-1ca552bd00e64c01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们知道：

![image](http://upload-images.jianshu.io/upload_images/5952841-5606719fde304207.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中的

![image](http://upload-images.jianshu.io/upload_images/5952841-a08ea59fdc37234d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

分别表示第2层神经元的输出的第1、2、3个神经元产生的值

这三个值经过第3层最后一个神经元计算后得出最终的输出是：

![image](http://upload-images.jianshu.io/upload_images/5952841-4b7ca0fb3411ed00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

以上神经网络如果有更多层，那么计算原理相同

我们发现这些神经元的激活函数f是相同的，唯一不同的就是权重W，那么我们做学习训练的目标就是求解这里的W，那么我们如何通过训练获得更精确的W呢？

### 反向传导算法

回想一下前面文章讲过的回归模型，我们也是知道大量训练样本(x,y)，未知的是参数W和b，那么我们计算W的方法是：先初始化一个不靠谱的W和b，然后用输入x和W和b预估y，然后根据预估的y和实际的y之间的差距来通过梯度下降法更新W和b，然后再继续下一轮迭代，最终逼近正确的W和b

神经网络算法也一样的道理，使用梯度下降法需要设计一个代价函数：

![image](http://upload-images.jianshu.io/upload_images/5952841-842d1efa11f6b8a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

以上是对于一个(x,y)的代价函数，那么当我们训练很多个样本时：

![image](http://upload-images.jianshu.io/upload_images/5952841-6568470bc64cbe42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中m是样本数，左项是均方差，右项是规则化项，我们的目的就是经过多伦迭代让代价函数最小

我来单独解释一下我对这个规则化项的理解：规则化项的目的是防止过拟合，过拟合的含义就是“太适合这些样本了，导致不适合样本之外的数据，泛化能力低”，规则化项首先增大了代价函数的值，因为我们训练的目的是减小代价函数，所以我们自然就会经过多轮计算逐步减小规则化项，规则化项里面是各个W的平方和，因为∑W=1，所以要想平方和变小，只有让各个W的值尽量相同，这就需要做一个折中，也就是W既要显示出各项权重的不同，又要降低差别，因此这里的λ的值就比较关键了，λ大了权重就都一样了，小了就过拟合了，所以需要根据经验给一个合适的值。

### 具体计算过程

首先我们为W和b初始化一个很小的随机值，然后分别对每个样本经过上面说过的神经网络的计算方法，计算出y的预估值

然后按照梯度下降法对W和b进行更新：

![image](http://upload-images.jianshu.io/upload_images/5952841-591035749ce81b36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里面最关键的是偏导的计算方法，对于最终的输出节点来说，代价函数J(W,b)的计算方法比较简单，就是把输出节点的激活值和实际值之间的残差代入J(W,B)公式。而隐藏层里的节点的代价函数该怎么计算呢？

我们根据前向传导（根据输入x计算hW,b(x)的方法）算法来反推：

我们把第l层的第i个节点的残差记作：

![image](http://upload-images.jianshu.io/upload_images/5952841-d25b01df7d1fed01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因为hW,b(x)=f(Wx)，这里面我们把Wx记作z，那么残差表达的其实是z的残差，也就是代价函数关于z的偏导

那么输出层的残差就是：

![image](http://upload-images.jianshu.io/upload_images/5952841-d71f64b55b0fbccc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

前一层的残差的推导公式为：

![image](http://upload-images.jianshu.io/upload_images/5952841-1e113ffd6191a430.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

再往前的每一层都按照这个公式计算得出残差，这个过程就叫做反向传导算法

下面在回过头来看我们的更新算法

![image](http://upload-images.jianshu.io/upload_images/5952841-2be6330520def532.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

偏导数的求法如下：

![image](http://upload-images.jianshu.io/upload_images/5952841-2e8efb5c8f2ab8e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

说一下我对这个公式的理解：代价函数对W的偏导表达的是权重(第l层上第i个节点第j个输入)的变化，而这个变化就是一个误差值，误差体现在哪里呢？体现在它影响到的下一层节点的残差δ，那么它对这个残差的影响有多大呢，在于它的输出值a，所以得出这个偏导就是aδ。代价函数对b的偏导原理类似。

现在我们有了所有的a和δ，就可以更新所有的W了，完成了一轮迭代

大家已经注意到了，在计算δ的方法中用到了f'(z)，这也就是激活函数的导数，现在明白为什么激活函数设计成sigmond或者tanh了吧？因为他们的导数更容易计算

### 总结一下整个计算过程

1. 初始化W和b为小随机数

2. 遍历所有样本，利用前向传导算法计算出神经网络的每一层输出a和最终的输出值hW,b(x)

3. 利用hW,b(x)和真实值y计算输出层的残差δ

4. 利用反向传导算法计算出所有层所有节点的残差δ

5. 利用每一层每一个节点的a和δ计算代价函数关于W和b的偏导

6. 用得出的偏导来更新权重

7. 返回2进行下一轮迭代直到代价函数不再收敛为止

8. 得到我们的神经网络

参考文献：UFLDL教程

## 用scikit-learn做逻辑回归

一元线性、多元线性、多项式回归都属于广义的线性回归，这几类线性回归主要用于预测连续变量的值。本节介绍广义线性回归的另一种主要用于分类任务的形式：逻辑回归。

### 二类分类问题

逻辑回归最广泛的应用就是二类分类，我们以脏话判别为例来利用逻辑回归，对一句话做脏话分析判断

输入样本如下：

是脏话：fuck you

是脏话：fuck you all

不是脏话：hello everyone

我们来预测以下两句话是否是脏话：

```
fuck me
hello boy
```

代码

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model.logistic import LogisticRegression

X = []

# 前三行作为输入样本
X.append("fuck you")
X.append("fuck you all")
X.append("hello everyone")

# 后两句作为测试样本
X.append("fuck me")
X.append("hello boy")

# y为样本标注
y = [1,1,0]

vectorizer = TfidfVectorizer()

# 取X的前三句作为输入做tfidf转换
X_train = vectorizer.fit_transform(X[:-2])

# 取X的后两句用上句生成的tfidf做转换
X_test = vectorizer.transform(X[-2:])

# 用逻辑回归模型做训练
classifier = LogisticRegression()
classifier.fit(X_train, y)

# 做测试样例的预测
predictions = classifier.predict(X_test)
print predictions
```

输出结果如下：

```
[1 0]
```

判断成：

是脏话：fuck me

不是脏话：hello boy
## 利用tensorflow做手写数字识别

[原文](http://www.shareditor.com/blogshow?blogId=94)

模式识别领域应用机器学习的场景非常多，手写识别就是其中一种，最简单的数字识别是一个多类分类问题，我们借这个多类分类问题来介绍一下google最新开源的tensorflow框架，后面深度学习的内容都会基于tensorflow来介绍和演示。

### 什么是tensorflow

tensor意思是张量，flow是流。

张量原本是力学里的术语，表示弹性介质中各点应力状态。在数学中，张量表示的是一种广义的“数量”，0阶张量就是标量(比如：0、1、2……)，1阶张量就是向量(比如：(1,3,4))，2阶张量就是矩阵，本来这几种形式是不相关的，但是都归为张量，是因为他们同时满足一些特性：1）可以用坐标系表示；2）在坐标变换中遵守同样的变换法则；3）有着相同的基本运算(如：加、减、乘、除、缩放、点积、对称……)

那么tensorflow可以理解为通过“流”的形式来处理张量的一种框架，是由google开发并开源，已经应用于google大脑项目开发

### tensorflow安装

[官网安装教程](https://www.tensorflow.org/install/)

推荐使用docker安装，免去配置cuda环境。

### 手写数字数据集获取

[github download](https://github.com/liqiang311/tf/tree/master/MNIST/MNIST_data)

在http://yann.lecun.com/exdb/mnist/ 可以下载手写数据集， http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz 和 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz ，下载解压后发现不是图片格式，而是自己特定的格式，为了说明这是什么样的数据，我写了一段程序来显示这些数字：

```c
/************************
 * author: SharEDITor
 * date:   2016-08-02
 * brief:  read MNIST data
 ************************/
#include <stdio.h>
#include <stdint.h>
#include <assert.h>
#include <stdlib.h>

unsigned char *lables = NULL;

/**
 * All the integers in the files are stored in the MSB first (high endian) format
 */
void copy_int(uint32_t *target, unsigned char *src)
{
    *(((unsigned char*)target)+0) = src[3];
    *(((unsigned char*)target)+1) = src[2];
    *(((unsigned char*)target)+2) = src[1];
    *(((unsigned char*)target)+3) = src[0];
}

int read_lables()
{
    FILE *fp = fopen("./train-labels.idx1-ubyte", "r");
    if (NULL == fp)
    {
        return -1;
    }
    unsigned char head[8];
    fread(head, sizeof(unsigned char), 8, fp);
    uint32_t magic_number = 0;
    uint32_t item_num = 0;
    copy_int(&magic_number, &head[0]);
    // magic number check
    assert(magic_number == 2049);
    copy_int(&item_num, &head[4]);

    uint64_t values_size = sizeof(unsigned char) * item_num;
    lables = (unsigned char*)malloc(values_size);
    fread(lables, sizeof(unsigned char), values_size, fp);

    fclose(fp);
    return 0;
}

int read_images()
{
    FILE *fp = fopen("./train-images.idx3-ubyte", "r");
    if (NULL == fp)
    {
        return -1;
    }
    unsigned char head[16];
    fread(head, sizeof(unsigned char), 16, fp);
    uint32_t magic_number = 0;
    uint32_t images_num = 0;
    uint32_t rows = 0;
    uint32_t cols = 0;
    copy_int(&magic_number, &head[0]);
    // magic number check
    assert(magic_number == 2051);
    copy_int(&images_num, &head[4]);
    copy_int(&rows, &head[8]);
    copy_int(&cols, &head[12]);

    uint64_t image_size = rows * cols;
    uint64_t values_size = sizeof(unsigned char) * images_num * rows * cols;
    unsigned char *values = (unsigned char*)malloc(values_size);
    fread(values, sizeof(unsigned char), values_size, fp);

    for (int image_index = 0; image_index < images_num; image_index++)
    {
        // print the label
        printf("=========================================  %d  ======================================\n", lables[image_index]);
        for (int row_index = 0; row_index < rows; row_index++)
        {
            for (int col_index = 0; col_index < cols; col_index++)
            {
                // print the pixels of image
                printf("%3d", values[image_index*image_size+row_index*cols+col_index]);
            }
            printf("\n");
        }
        printf("\n");
    }

    free(values);
    fclose(fp);
    return 0;
}

int main(int argc, char *argv[])
{
    if (-1 == read_lables())
    {
        return -1;
    }
    if (-1 == read_images())
    {
        return -1;
    }
    return 0;
}
```

下载并解压出数据集文件train-images.idx3-ubyte和train-labels.idx1-ubyte放到源代码所在目录后，编译并执行：

```bash
gcc -o read_images read_images.c
./read_images
```

一共有60000个图片，从代码可以看出数据集里存储的实际就是图片的像素

### softmax模型

逻辑回归是用于解决二类分类问题(使用sigmoid函数)，而softmax模型是逻辑回归模型的扩展，用来解决多类分类问题。

softmax意为柔和的最大值，也就是如果某个zj大于其他z，那么这个映射的分量就逼近于1，其他的分量就逼近于0，从而将其归为此分类，多个分量对应的就是多分类，数学形式和sigmoid不同，如下：

![image](http://upload-images.jianshu.io/upload_images/5952841-3d551c0d9ea1f132.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

它的特点是，所有的softmax加和为1，其实它表示的是一种概率，即x属于某个分类的概率。

在做样本训练时，这里的xi计算方法是：

![image](http://upload-images.jianshu.io/upload_images/5952841-a3d3591d351f4b9e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中W是样本特征的权重，xj是样本的特征值，bi是偏置量。

详细来说就是：假设某个模型训练中我们设计两个特征，他们的值分别是f1和f2，他们对于第i类的权重分别是0.2和0.8，偏置量是1，那么

xi=f1*0.2+f2*0.8+1

如果所有的类别都计算出x的值，如果是一个训练好的模型，那么应该是所属的那个类别对应的softmax值最大

softmax回归算法也正是基于这个原理，通过大量样本来训练这里的W和b，从而用于分类的

### tensorflow的优点

tensorflow会使用外部语言计算复杂运算来提高效率，但是不同语言之间的切换和不同计算资源之间的数据传输耗费很多资源，因此它使用图来描述一系列计算操作，然后一起传给外部计算，最后结果只传回一次，这样传输代价最低，计算效率最高

举个例子：

```python
import tensorflow as tf
x = tf.placeholder(tf.float32, [None, 784])
```

这里的x不是一个实际的x，而是一个占位符，也就是一个描述，描述成了二维浮点型，后面需要用实际的值来填充，这就类似于printf("%d", 10)中的占位符%d，其中第一维是None表示可无限扩张，第二维是784个浮点型变量

如果想定义可修改的张量，可以这样定义：

```python
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
```

其中W的维度是[784, 10]，b的形状是[10]

有了这三个变量，我们可以定义我们的softmax模型：

```python
y = tf.nn.softmax(tf.matmul(x,W) + b)
```

这虽然定义，但是没有真正的进行计算，因为这只是先用图来描述计算操作

其中matmul是矩阵乘法，因为x的维度是[None, 784]，W的维度是[784, 10]，所以矩阵乘法得出的是[None, 10]，这样可以和向量b相加

softmax函数会计算出10维分量的概率值，也就是y的形状是[10]

### 数字识别模型实现

基于上面定义的x、W、b，和我们定义的模型：

```python
y = tf.nn.softmax(tf.matmul(x,W) + b)
```

我们需要定义我们的目标函数，我们以交叉熵(衡量预测用于描述真相的低效性)为目标函数，让它达到最小：

![image](http://upload-images.jianshu.io/upload_images/5952841-81c6d02c6bf847f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中y'是实际分布，y是预测的分布，即：

```python
y_ = tf.placeholder("float", [None,10])
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
```

利用梯度下降法优化上面定义的Variable：

```python
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
```

其中0.01是学习速率，也就是每次对变量做多大的修正

按照上面的思路，最终实现的代码digital_recognition.py如下：

```python
# coding:utf-8

import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_string('data_dir', './', 'Directory for storing data')

mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)


x = tf.placeholder(tf.float32, [None, 784])
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x,W) + b)
y_ = tf.placeholder("float", [None,10])
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)

init = tf.initialize_all_variables()
sess = tf.InteractiveSession()
sess.run(init)
for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))
```

输出0.9199

解释一下

```python
flags.DEFINE_string('data_dir', './', 'Directory for storing data')
```

表示我们用当前目录作为训练数据的存储目录，如果我们没有提前下好训练数据和测试数据，程序会自动帮我们下载到./

```python
mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
```

这句直接用库里帮我们实现好的读取训练数据的方法，无需自行解析

```python
for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
```

这几行表示我们循环1000次，每次从训练样本里选取100个样本来做训练，这样我们可以修改配置来观察运行速度

最后几行打印预测精度，当调整循环次数时可以发现总训练的样本数越多，精度就越高
